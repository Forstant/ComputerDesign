评论,时间,点赞数,标签
像这种游戏，AI实话说学习能力并没有人类强，只不过他有大量的时间和大量次数进行训练，给人类相同的时间和训练次数，一定能比AI做得好。不过人类处理数据的能力有极限，像围棋这种就永远打不过AI[捂脸],2023-01-28 14:03:10,6,0
我们人工智能的教授说，现阶段的人工智能，做出来的有多智能，相应的就有多少人工[兔年],2023-01-28 12:40:49,7,0
看完之后有很多启发，这个笨蛋一样的AI就像是我自己，进步的很缓慢，总是各种各样的形式翻车。但是假以时日，用更多更多的失败来累计也能完成这场游戏。如果找到了合适的训练方法，或许也能比别人做的更好一些。,2023-01-29 10:41:51,3,0
"之前课设也做过类似的小游戏，当时用了个简单的遗传算法，用当前小车各个方向到边缘的距离和当前的速度作为输入，并且设置了和视频中类似的奖励函数来评价每个agent的分数。问题就在于可能出现无法关注到长远情况的问题，比如在弯道处加速以获得短时间内的高分，而之后撞墙死掉的情况。
最后处理的方法是把网络改成卷积网络，用颜色标出赛道的边缘，然后把当前赛道和车的图像送进网络，可以解决上述问题。
之后就一直在思考，在我们已知整张地图的结构时确实可以使用以上方法训练，但如果是真实的自动驾驶场景很难获取到这样只够全局的数据作为输入去，可能输入的只能是一些当前的状态量。那么这种情况下如何避免网络出现以上的问题？不知道当前业界采用的解决方案思路是什么",2023-01-29 09:36:06,3,0
我有个想法，如果让机器自主选择使用的算法的话，它能不能自己找到最好的算法[微笑],2023-01-29 04:04:31,3,0
只输入下一个弯道数据也太欺负ai了吧，直角弯和U弯的过弯策略是完全不一样的，人眼可以轻松识别采取策略，AI却需要转过U弯的第一个弯才能获取下面的数据，自然就慢了，要是能获取至少后两个弯的数据，我想AI不弱于人类操作。[藏狐],2023-01-28 17:05:39,9,0
我让猩猩随便乱打一长串文字，只要我够幸运或者猩猩（基数）够多，它就能写好一篇文章,2023-01-28 16:47:57,3,0
这是我看到的，把ai训练说得最清楚的视频[OK][OK][OK],2023-01-28 16:27:12,6,0
"这种算法差于人类的地方在于人类会进行长时预测，会为了下一个甚至下几个弯对当前策略进行调整，玩赛车游戏多的就知道，为了尽量少吃变向减速，要贴弯过，而贴弯过是一种危险的车体朝向，为了尽量快的安全，要提前安排车辆的转弯空间。
这个过程是可以利用数学进行计算的，专门编一个程序的话可以办最优路线和最优操作。
但，本视频的算法的研究目的在于可以任意套用任何情形进行算法编写和算法优化，是算法写算法，而我说的那种仍然是人写算法，价值方向不同，行为本身间没有优劣之分",2023-01-28 14:50:43,7,0
ai强大在你让它学它真得会去学,2023-01-28 09:06:16,7,0
我就我玩游戏的经验来看，大部分游戏里的ai都像评论第一说的那样看着聪明，你要说优势在那里就是随机应变的能力比ai强太多了。,2023-01-28 06:56:37,3,0
赛道狂飙真的是特别适合练AI的游戏，没有任何随机变量操作输入造成的结果是绝对固定的。,2023-01-28 05:44:57,3,0
赛道狂飙！这游戏我还玩过！,2023-01-28 05:13:24,3,0
视频真的高质量，不过英语感觉毛子味很浓[吃瓜],2023-01-28 04:23:58,6,0
"说AI就AI不要加入各种拟人化操作，AI和神经元没有任何关系，也没有什么学习。强化学习主要就是在无数据或无标准固定数据中根据认为设定向建立函数对输入数据进行分类归纳，所谓遗传就是，好比有同时有n个AI程序在完游戏每一次迭代都继承前面好的几个网络参数，相当于完游戏里面二周目继承。这样不断继承就会得到一个奖励函数最高的分类，这就是本质，没有所谓学习和神经元，神经元和学习都是深度训练领域那些人搞出来拟人化操作，我其实非常反感这种用词。至于你后面说的那种预训练，本质就是深度强化训练，up用的是单纯强化训练，不要从零开始只能用结合深度训练，深度训练玩家们游戏数据。现在大部分领域用的都是深度强化训练。
AI所谓结果每次迭代操作基本上是稳定的。但是人做不上稳定，人会受情绪影响，有操作失误。AI训练成型后之后按照既定的逻辑代码运行，这就是最本质区别，前者不稳定后者AI稳定",2023-01-28 02:07:02,22,0
ai这算算力？背板是ai，我们需要的是随机应变不是背板啊。,2023-01-28 01:08:34,42,0
這個視頻把深度學習的思路和難點講得好清晰呀,2023-01-27 22:00:57,3,0
因为这是无源数据集（或者说初始是随机数据集）的强化学习，小孩对于动感事物的控制能力是刻在DNA里的，如果这个AI是个大型的强AI（模拟人脑与各感官的大部分基础功能与互动），肯定会大大减少训练时间，这也是为什么要搞预训练模型（类似GPT）,2023-01-27 19:45:36,6,0
有点像蚂蚁……无数的ai，每个ai间都有所不同，某些有所改变，可以形成无数的可能。在这之中，一定有运动更远的，那么下次运行就依托这个变化而进行……周而复始，一定能倾向于权重方发展,2023-01-27 18:49:18,3,0
我觉得有一个开不快的原因是走线问题，因为得分点在路中间，所以ai会更倾向于待在路中间，而不会提前靠边,2023-01-27 13:13:38,9,0
有没有一种可能 你说的人类已经经过了大量的“预训练” 跟ai对比不太公平,2023-01-28 16:01:23,5,0
关键是人不能在相同的时间里完成那么多次训练,2023-01-28 14:05:14,4,0
几年十几年甚至几十年的生活/游戏经验，这东西可没法直接扔进ai数据库里[吃瓜],2023-01-29 02:10:44,0,0
人工智能人工智能，先有人工才能智能,2023-01-28 12:44:59,0,0
首先，你比那智障聪明，第二，你的试错有成本，而且你不会时间加速,2023-02-03 10:32:26,0,0
回复 @难光 : 生活一向很残酷,2023-01-29 13:46:12,0,0
有时候，我们没有这么多试错的机会[无语],2023-01-29 10:42:37,0,0
"这个问题我觉得非常奇怪，训练的时候是在学习，自动驾驶的时候是在考试。这两个是相互独立的过程。
把包含各种路面情况的地图模拟出来给AI学习，学习之后再用这个模型来作用在自动驾驶中，已经把模型运用了，为什么我还需要全局的数据来输入？对于未来的考量，我是在学习阶段学到的呀。",2023-02-01 20:14:15,1,0
解决了你也能造特斯拉了[脱单doge]，你就是下一个马斯克,2023-02-09 03:43:31,0,0
"回复 @这真是无聊透顶 :确实是这样，可能需要模拟的情况更复杂时，还需要修改模型的结构，使其能拟合更复杂的情形。同时还需要考虑到车载终端的推理速度。之前做过嵌入式相关的ai开发，很能体会到在小型平台上算力的局促。
想想也是，各家自动驾驶的实现方式应该也不会开源，学术界的研究毕竟还是缺乏对工程问题的考虑，这些具体问题可能只有业界人士才能知道得比较清楚了。",2023-02-02 15:01:54,0,0
已经有了,2023-01-29 04:11:44,0,0
automl,2023-01-29 04:21:02,0,0
回复 @SephiHorse :感谢解答[doge],2023-01-29 06:06:38,0,0
超级对。但是数据量越多，训练量也越大，可能是基于一些现实中的考量。,2023-02-02 06:53:18,0,0
猩猩，红楼梦，穷举的经典解释,2023-01-28 17:02:01,1,0
机器学习可不是猴子打字机，在训练过程是有正反馈的,2023-01-29 01:04:14,1,0
AI会进步，而猩猩不会，你让打出一篇文章的猩猩再试一次，它还是会乱打，而AI则会以更好的成绩再完成一次目标,2023-01-29 04:09:10,4,0
这么强的技术，肯定是阿三口音呀[吃瓜],2023-01-28 05:04:21,0,0
是毛子味还是咖喱味 [打call],2023-01-28 05:13:29,0,0
阿这，你这也太云了吧[思考]，作者使用的算法是dqn，对应的论文就是强化学习领域的经典作deep qlearning，里面就是在用神经网络拟合累计奖励函数，你这好歹先对这个领域有点了解再来发言吧。谁跟你说这东西和遗传算法是一样的了[笑哭]。况且机器学习发展这么多年，就类似于决策树模型、支持向量机模型，神经网络也只是其中一种拟合数据的方式，以此来实现回归或分类而已，这和拟人化有什么关系。。。。,2023-01-28 03:17:42,23,0
回复 @沐秋の友人帐 :他懂个屁，你跟他说这个,2023-01-28 05:04:50,5,0
层主的意思似乎抨击那些看似高大上晦涩难懂的命名。由于每个人知识领域基础不同，所以喜欢的命名术语方式不一样。实际上如果跨多领域学习过，就感觉到有些专业术语很晦涩，实际机理没那么难理解，完全可以用low一些的词汇更好的描述。比如神经元这种词汇，不太适合dev出生领域去理解，反而会很晦涩，用状态归类这种说法更加适合dev人员理解。再比如我反过来以dev对你说注册对象...贫血模型，可能对非dev工程学出生的人来说也是一脸懵逼。至于深度学习...其实是感知机层数多了所以叫深度...对于刚学ai的人来说也是很晦涩的词汇，不了解ai发展历史也会一脸懵逼,2023-01-28 05:31:14,3,0
显然你没有看到最后,2023-01-28 01:39:53,35,0
人和ai表现在外的区别只是人会直接剔除一上来就往沟里开的路线，ai比较笨，它要掉到沟里去试一试才知道不行，人的熟能生巧本身就是背板,2023-01-28 02:20:22,34,0
回复 @yano丶erika :其实人在婴幼儿时期也不会剔除那些显而易见的常识性错误。婴幼儿时期的大量预训练才让人能应对多模态的任务,2023-01-28 05:18:29,0,0
不是强化学习嘛,2023-01-28 00:01:01,1,0
你是否在找 蚁群算法[doge],2023-01-28 02:40:03,3,0
可以去看一下涌现效应,2023-01-28 05:09:55,0,0
强化学习对赋分机制太依赖了，效果基本上就是依靠人类人为的设置得分规则,2023-01-27 15:22:01,5,0
拐弯处不设得分点能解决吗,2023-01-28 02:34:41,0,0
回复 @地产有合适 :我觉得，就是让职业赛车手跑一遍，然后得分点按他们的路径设置,2023-01-28 03:20:21,0,0
