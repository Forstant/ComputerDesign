评论,时间,点赞数,标签
如果在公司我写的代码上线后有bug造成损失会负责任吗？,2023-02-19 16:39:00,2,0
谢谢分享[歪嘴],2023-02-19 13:31:24,2,0
up随笔几句 兄弟学到很多 谢谢,2023-02-19 12:56:16,2,0
没看懂，他给的东西问题在哪里？ 还有全局sql语句监控，这个怎么做？,2023-02-18 14:26:56,2,0
所以这跟拼接sql没关系，还是开发人员经验不足导致。,2023-02-18 09:04:32,2,0
程序猿怎么面对35岁不好找工作问题？,2023-02-26 02:11:52,2,0
分页中是要返回总条数给前端，那这种大查询下的count怎么优化呢,2023-02-17 14:27:40,6,0
"呢个sql jiankong,druid 不久可以开启么",2023-02-17 10:51:01,4,0
用mp全都写在代码里去写逻辑，感觉更直观，不是很喜欢xml,2023-02-17 15:03:26,10,0
你这发量将这个很难让人信服，瞅你也不像技术组的,2023-02-23 22:29:14,2,0
哥，还是不太明白，复用同事的sql为啥会出这么大的问题呢,2023-02-18 10:58:49,2,0
"个人理解：复用别人查询容易出问题，其实自己写也一样存在类似的问题。
如果自己写的时候能在sql有意识的加limit，复用别人的时候也可以有意识在业务层通过分页插件限制。",2023-02-17 10:57:15,18,0
啊[doge]看来我思维还是挺严谨的，在上一家小公司我做后端开发也想到过类似问题（虽然那软件估计用户上限就4位数），某些重要参数我会在接口做检测，不传我直接返回，另外我会确保我回传的数据不会超过一定数量，一般会做分页，如果没有分页我只传部分数据，并给前端提示（虽然前端没有对应的处理）,2023-02-17 16:18:56,16,0
这个问题和是不是在别人sql上加条件没关系吧，只要加的不是OR条件，理论上一定会小于等于加条件之前查出的数据，而这个问题主要还是因为LIMIT没有限制导致的,2023-02-17 15:42:53,13,0
我现在做的一个系统，是一个服务器的用量监控，数据库里存的是服务器每小时的用量，用户想看一整年的图表，我现在的解决方法是查一年的8736条数据，在java里每168条(一周)算平均值，然后返回52条数据给前端[笑哭],2023-02-17 10:22:17,25,0
"up说的很好，点赞投币了！
然后也想问问up，慢查询监控，全局查询监控，查询个数监控，改sql加limit这些，都可以在德鲁伊实现吗？",2023-02-18 12:59:20,4,0
"做了一个切面 @Page 会将函数里第一条mapper进行拦截 最后对分页结果打包 整体流程1.分页参数校验和修正后 PageHelper.startPage 2.执行mapper 3.打包分页结果 自动把page、size、total这些封装返回给controller层。
结果上次  在需要分页的mapper前 写了个类型mapper查询 导致分页失效 查询回来1万多条 幸亏是测试环境 长记性了",2023-02-17 10:58:41,28,0
视频没讲清楚怎么会查出很多条数据的原因啊,2023-02-17 15:10:15,3,0
我觉得连接池就连接池 别放条件啊 别作死。。用共通方法一定要在共通方法设计书加入你也调用了。。,2023-02-18 11:49:15,2,0
foreach不走缓存，sql语句得从新加载，foreach拼接参数过多会消耗大量时间，会随着拼接数量呈指数增长，一般最优是在50左右，100以后就明显呈指数曾长。还有order by 字段动态拼接，排序数量过多会导致索引失效？还有就是深分页，一般你用不到，除非你做数据推送，深分页优化方案书签，子查询，join。,2023-02-17 13:22:46,14,0
项目经理负责,2023-03-05 00:09:20,0,0
你给的语句里有limit啊 为什么还会查出很多？,2023-02-19 01:10:49,0,0
怕什么，你好歹还是程序员，我40出头的运维，做到客户都倒闭不是照样继续[滑稽]，只要没房贷，生命自会找到出路[脱单doge],2023-03-02 10:20:18,0,0
1瀑布流分页，2缓存count 当count大到一定数量是否精确没有任何意义,2023-03-02 23:12:04,0,0
用next page链接的方式，不让用户跳页,2023-02-22 16:34:03,0,0
"回复 @御风大世界 : 曾经mysql 查询返回数据 与 程序返回数据不一致, 被搞过...
本质就是 druid 会 注册个拦截器, 在statement 生成时候将自己的判断条件 加在sql 语句上.[藏狐]",2023-02-17 11:10:32,2,0
你是懂的,2023-02-17 11:03:29,0,0
"sql 监控, 以及 后面的limit 限制 druid 都可以配置的./doge[doge]",2023-02-17 10:53:45,0,0
认真的吗[辣眼睛]连表查笛卡尔积+new对象＝堆爆炸＝跑路，无用的数据就不应该从数据库里跑出来，浪费带宽+时间,2023-02-23 11:02:33,1,0
回复 @俊采丿星驰 :可以每次都根据主键查单表组成list然后在service层拼接嘛。这样数据库压力也小了不是,2023-02-22 16:47:15,0,0
回复 @朝浦潓汐 :有学习成本，毕竟sql才是通用的,2023-02-19 07:44:14,0,0
回复 @区分小谢 :Sql没有用where过滤查询条件吗,2023-02-19 00:46:34,0,0
没做查询条数限制，导致查全表了，数据量太大。,2023-02-18 16:33:07,0,0
关键是复用呀，不同场景入参不一样，查询结果怎么可能保证是一样的呢,2023-02-24 19:31:52,0,0
除非是涉及到表链接，否则淡出加查询条件应该不会出这种问题,2023-02-18 16:41:09,0,0
是啊，看得我有些奇怪，自己写不也一样没用到别人的条件吗,2023-02-17 16:54:11,0,0
回复 @不败的R :我也做过这种需求，搞了个监控每30秒记录一次cpu内存占用，然后用户要看一星期的资源占用，我开始也是想全部拉出来求平均，但是数据量太大了，后面我直接只取整点的数据返回回去。但是这样不能精确反映资源占用。其实要高吞吐高并发无非就3种办法，加资源，同步改异步增加资源利用率，数据提前准备好空间换时间[doge],2023-02-17 17:10:49,7,0
可以参考zabbix的，定期做数据清洗，把超过设定时间（默认一个月）的数据做平均，或者别的，把颗粒度调整一下。因为一个月以后，很少会查询精确时间的数据了,2023-02-17 21:54:20,2,0
另外也可以在数据库里启定时存储过程或者java启定时任务然后在每天2-3点算好平均值存在表里，然后直接查这张表,2023-02-17 10:30:03,2,0
mybatis可以实现 通过拦截器,2023-02-21 00:15:49,0,0
数据库有专门的系统表记录慢查询,2023-02-19 16:20:56,0,0
回复 @白马入梦 :sql硬加个limit是非常不合理的，从业务上就应该限制死几个必传条件，哪有用户查全表的场景。,2023-02-17 17:23:40,1,0
查询条件满足if的一个都没有又没有分页 直接返回了全表数据,2023-02-17 16:55:47,0,0
确实，感觉说的时间太长了，这样的一个小故障问题视频都11分钟，现在的年轻人普遍喜欢5分钟以内的视频，何况这又是一个解决小bug的技术视频，希望可以缩短一点时间吧。,2023-02-17 16:32:01,0,0
单次查询数量过多，可以使用游标。ES返回超过一万，使用游标，同时禁止分数排序，7kw数据大概一小时（还有线程休眠进行调速)。,2023-02-17 13:28:02,1,0
[doge][doge][doge]给我们讲讲你的事故,2023-02-17 10:13:53,27,0
想看每天一个技术规范及踩坑事故,2023-02-17 14:31:37,22,0
回复 @yasashiiplace : 对,2023-02-24 02:10:06,0,0
[doge][doge][doge]给我们讲讲你的事故,2023-02-17 10:13:53,27,0
想看每天一个技术规范及踩坑事故,2023-02-17 14:31:37,22,0
回复 @yasashiiplace : 对,2023-02-24 02:10:06,0,0
